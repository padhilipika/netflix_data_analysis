{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"11Tlhjbh_-MVPmzLLnOZZN32os-Cnhaha","timestamp":1692214013961},{"file_id":"1pLHuk5ml8brfq76USc0n0suZU4FLxCqd","timestamp":1690490427860}],"collapsed_sections":["vncDsAP0Gaoa","FJNUwmbgGyua","yQaldy8SH6Dl","PH-0ReGfmX4f","mDgbUHAGgjLW","O_i_v8NEhb9l","HhfV-JJviCcP","Y3lxredqlCYt","3RnN4peoiCZX","x71ZqKXriCWQ","7hBIi_osiCS2","JlHwYmJAmNHm","35m5QtbWiB9F","PoPl-ycgm1ru","H0kj-8xxnORC","nA9Y7ga8ng1Z","PBTbrJXOngz2","u3PMJOP6ngxN","dauF4eBmngu3","bKJF3rekwFvQ","MSa1f5Uengrz","GF8Ens_Soomf","0wOQAZs5pc--","K5QZ13OEpz2H","lQ7QKXXCp7Bj","448CDAPjqfQr","KSlN3yHqYklG","t6dVpIINYklI","ijmpgYnKYklI","-JiQyfWJYklI","EM7whBJCYoAo","fge-S5ZAYoAp","85gYPyotYoAp","RoGjAbkUYoAp","4Of9eVA-YrdM","iky9q4vBYrdO","F6T5p64dYrdO","y-Ehk30pYrdP","bamQiAODYuh1","QHF8YVU7Yuh3","GwzvFGzlYuh3","qYpmQ266Yuh3","OH-pJp9IphqM","bbFf2-_FphqN","_ouA3fa0phqN","Seke61FWphqN","PIIx-8_IphqN","t27r6nlMphqO","r2jJGEOYphqO","b0JNsNcRphqO","BZR9WyysphqO","jj7wYXLtphqO","eZrbJ2SmphqO","rFu4xreNphqO","gCFgpxoyphqP","OVtJsKN_phqQ","lssrdh5qphqQ","U2RJ9gkRphqQ","1M8mcRywphqQ","tgIPom80phqQ","JMzcOPDDphqR","x-EpHcCOp1ci","X_VqEhTip1ck","8zGJKyg5p1ck","PVzmfK_Ep1ck","n3dbpmDWp1ck","ylSl6qgtp1ck","ZWILFDl5p1ck","M7G43BXep1ck","Ag9LCva-p1cl","E6MkPsBcp1cl","2cELzS2fp1cl","3MPXvC8up1cl","NC_X3p0fY2L0","UV0SzAkaZNRQ","YPEH6qLeZNRQ","q29F0dvdveiT","EXh0U9oCveiU","22aHeOlLveiV","JcMwzZxoAimU","8G2x9gOozGDZ","gCX9965dhzqZ","gIfDvo9L0UH2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Project Name** --  Netflix Movies and TV Shows Clustering**\n","\n"],"metadata":{"id":"vncDsAP0Gaoa"}},{"cell_type":"markdown","source":["##### **Project Type**    - Unsupervised\n","##### **Contribution**    - Individual"],"metadata":{"id":"beRrZCGUAJYm"}},{"cell_type":"markdown","source":["# **Project Summary -**\n","\n"],"metadata":{"id":"FJNUwmbgGyua"}},{"cell_type":"markdown","source":["Write the summary here within 500-600 words.\n","\n","The goal of this project is to analyze the Netflix catalog of movies and TV shows, which was sourced from the third-party search engine Flixable, and group them into relevant clusters. This will aid in enhancing the user experience and prevent subscriber churn for the world's largest online streaming service provider, Netflix, which currently boasts over 220 million subscribers as of 2022-Q2. The dataset, which includes movies and TV shows as of 2019, will be analyzed to uncover new insights and trends in the rapidly growing world of streaming entertainment.\n","\n","* There were approximately 7787 records and 11 attributes in the dataset.\n","\n","* We started by working on the missing values in the dataset and conducting exploratory data analysis (EDA).\n","\n","* Using the following attributes to create a cluster: cast, country, genre, director, rating, and description The TFIDF vectorizer was used to tokenize, preprocess, and vectorize the values in these attributes.\n","\n","* The problem of dimensionality was dealt with through the use of Principal Component Analysis (PCA).\n","\n","* Using a variety of methods, including the elbow method, silhouette score, dendrogram, and others, we constructed two distinct types of clusters with the K-Means Clustering and Agglomerative Hierarchical clustering algorithms, respectively, and determined the optimal number of clusters.\n","\n","* The similarity matrix generated by applying cosine similarity was used to construct a content-based recommender system. The user will receive ten recommendations from this recommender system based on the type of show they watched."],"metadata":{"id":"F6v_1wHtG2nS"}},{"cell_type":"markdown","source":["# **GitHub Link -**"],"metadata":{"id":"w6K7xa23Elo4"}},{"cell_type":"markdown","source":["Provide your GitHub Link here.\n","\n","https://github.com/padhilipika\n","\n","\n","\n"],"metadata":{"id":"h1o69JH3Eqqn"}},{"cell_type":"markdown","source":["# **Problem Statement**\n"],"metadata":{"id":"yQaldy8SH6Dl"}},{"cell_type":"markdown","source":["**Write Problem Statement Here.**\n","\n","\n","\n","Netflix is a streaming service that offers a wide variety of television shows and movies for viewers to watch at their convenience. With a monthly subscription, users have access to a vast library of content, including original series and films produced by Netflix. The platform also allows users to create multiple profiles, making it easy for family members or roommates to have their own personalized viewing experience. Additionally, Netflix allows users to download content to watch offline, making it a great option for those who travel frequently or have limited internet access. Overall, Netflix is a convenient and cost-effective way to access a wide variety of entertainment.\n","\n","As of 2022-Q2, more than 220 million people had signed up for Netflix's online streaming service, making it the largest OTT provider worldwide. To improve the user experience and prevent subscriber churn, they must efficiently cluster the shows hosted on their platform.\n","\n","By creating clusters, we will be able to comprehend the shows that are alike and different from one another. These clusters can be used to provide customers with individualized show recommendations based on their preferences.\n","\n","This project aims to classify and group Netflix shows into specific clusters in such a way that shows in the same cluster are similar to one another and shows in different clusters are different."],"metadata":{"id":"DpeJGUA3kjGy"}},{"cell_type":"markdown","source":["#### **Define Your Business Objective?**"],"metadata":{"id":"PH-0ReGfmX4f"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","To enhance the user experience and reduce subscriber churn on Netflix by providing personalized show recommendations based on show clustering."],"metadata":{"id":"PhDvGCAqmjP1"}},{"cell_type":"markdown","source":["# **General Guidelines** : -  "],"metadata":{"id":"mDgbUHAGgjLW"}},{"cell_type":"markdown","source":["1.   Well-structured, formatted, and commented code is required.\n","2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n","     \n","     The additional credits will have advantages over other students during Star Student selection.\n","       \n","             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n","                       without a single error logged. ]\n","\n","3.   Each and every logic should have proper comments.\n","4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n","        \n","\n","```\n","# Chart visualization code\n","```\n","            \n","\n","*   Why did you pick the specific chart?\n","*   What is/are the insight(s) found from the chart?\n","* Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n","5. You have to create at least 20 logical & meaningful charts having important insights.\n","\n","\n","[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n","\n","U - Univariate Analysis,\n","\n","B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n","\n","M - Multivariate Analysis\n"," ]\n","\n","\n","\n"],"metadata":{"id":"ZrxVaUj-hHfC"}},{"cell_type":"markdown","source":["# ***Let's Begin !***"],"metadata":{"id":"O_i_v8NEhb9l"}},{"cell_type":"markdown","source":["## ***1. Know Your Data***"],"metadata":{"id":"HhfV-JJviCcP"}},{"cell_type":"markdown","source":["### Import Libraries\n"],"metadata":{"id":"Y3lxredqlCYt"}},{"cell_type":"code","source":["# Import Libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","# Word Cloud library\n","from wordcloud import WordCloud, STOPWORDS\n","\n","# libraries used to process textual data\n","import string\n","string.punctuation\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","from nltk.stem.snowball import SnowballStemmer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import PCA\n","\n","# libraries used to implement clusters\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","from sklearn.cluster import AgglomerativeClustering\n","import scipy.cluster.hierarchy as shc\n","\n","# libraries that are used to construct a recommendation system\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Library of warnings would assist in ignoring warnings issued\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"M8Vqi-pPk-HR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Loading"],"metadata":{"id":"3RnN4peoiCZX"}},{"cell_type":"code","source":["# Load Dataset\n","from google.colab import files\n","uploaded = files.upload()\n","df = pd.read_csv('NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"],"metadata":{"id":"4CkvbW_SlZ_R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset First View"],"metadata":{"id":"x71ZqKXriCWQ"}},{"cell_type":"code","source":["# Dataset First Look (Viewing the first 5 rows)\n","df.head()"],"metadata":{"id":"LWNFOSvLl09H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset First Look( Viewing the last 5 rows)\n","df.tail()\n"],"metadata":{"id":"Ol2JSPx9Wzcy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Rows & Columns count"],"metadata":{"id":"7hBIi_osiCS2"}},{"cell_type":"code","source":["# Dataset Rows & Columns count\n","df.shape"],"metadata":{"id":"Kllu7SJgmLij"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'number of rows : {df.shape[0]}  \\nnumber of columns : {df.shape[1]}')"],"metadata":{"id":"yvqqc-y-XG_a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Information"],"metadata":{"id":"JlHwYmJAmNHm"}},{"cell_type":"code","source":["# Dataset Info\n","df.info()"],"metadata":{"id":"e9hRXRi6meOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Duplicate Values"],"metadata":{"id":"35m5QtbWiB9F"}},{"cell_type":"code","source":["# Dataset Duplicate Value Count\n","value = len(df[df.duplicated()])\n","print(\"The number of duplicate values in the data set is = \",value)"],"metadata":{"id":"1sLdpKYkmox0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hence we found that were no duplicate entries in the above data."],"metadata":{"id":"OsglDAd8Xh2A"}},{"cell_type":"markdown","source":["#### Missing Values/Null Values"],"metadata":{"id":"PoPl-ycgm1ru"}},{"cell_type":"code","source":["# Missing Values/Null Values Count\n","print(df.isnull().sum())"],"metadata":{"id":"GgHWkxvamxVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing the missing values\n","import missingno as msno\n","msno.bar(df, color='green',sort='ascending', figsize=(10,3), fontsize=15)"],"metadata":{"id":"3q5wnI3om9sJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing the missing values using Heatmap\n","plt.figure(figsize=(12,4))\n","sns.heatmap(df.isna(), cmap = 'coolwarm')"],"metadata":{"id":"_KMO6x6jX8TS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What did you know about your dataset?"],"metadata":{"id":"H0kj-8xxnORC"}},{"cell_type":"markdown","source":["Answer Here\n","\n","\n","The given dataset is from the online streaming industry; our task is to examine the dataset, build the clustering methods and content based recommendation system.\n","\n","Clustering is a technique used in machine learning and data mining to group similar data points together. A clustering algorithm is a method or technique used to identify clusters within a dataset. These clusters represent natural groupings of the data, and the goal of clustering is to discover these groupings without any prior knowledge of the groupings.\n","\n","* There are 7787 rows and 12 columns in the dataset. In the director, cast, country, date_added, and rating columns, there are missing values. The dataset does not contain any duplicate values.\n","\n","* Every row of information we have relates to a specific movie. Therefore, we are unable to use any method to impute any null values. Additionally, due to the small size of the data, we do not want to lose any data, so after analyzing each column, we simply impute numeric values using an empty string in the following procedure."],"metadata":{"id":"gfoNAAC-nUe_"}},{"cell_type":"markdown","source":["## ***2. Understanding Your Variables***"],"metadata":{"id":"nA9Y7ga8ng1Z"}},{"cell_type":"code","source":["# Dataset Columns\n","df.columns"],"metadata":{"id":"j7xfkqrt5Ag5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset Describe\n","df.describe()"],"metadata":{"id":"DnOaZdaE5Q5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Variables Description"],"metadata":{"id":"PBTbrJXOngz2"}},{"cell_type":"markdown","source":["Answer Here\n","* **show_id :** Unique ID for every Movie/Show\n","* **type :** Identifier - Movie/Show\n","* **title :** Title of the Movie/Show\n","* **director :** Director of the Movie/Show\n","* **cast :** Actors involved in the Movie/Show\n","* **country :** Country where the Movie/Show was produced\n","* **date_added :** Date it was added on Netflix\n","* **release_year :** Actual Release year of the Movie/Show\n","* **rating :** TV Rating of the Movie/Show\n","* **duration :** Total Duration - in minutes or number of seasons\n","* **listed_in :** Genre\n","* **description :** The Summary description"],"metadata":{"id":"aJV4KIxSnxay"}},{"cell_type":"markdown","source":["### Check Unique Values for each variable."],"metadata":{"id":"u3PMJOP6ngxN"}},{"cell_type":"code","source":["# Check Unique Values for each variable.\n","for i in df.columns.tolist():\n","  print(\"No. of unique values in\",i,\"is\",df[i].nunique())"],"metadata":{"id":"zms12Yq5n-jE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. ***Data Wrangling***"],"metadata":{"id":"dauF4eBmngu3"}},{"cell_type":"markdown","source":["### Data Wrangling Code"],"metadata":{"id":"bKJF3rekwFvQ"}},{"cell_type":"code","source":["# Write your code to make your dataset analysis ready.\n","# Dataset First Look (Viewing the first 5 rows)\n","df.head()\n","# Dataset last Look (Viewing the first 5 rows)\n","df.tail()"],"metadata":{"id":"wk-9a2fpoLcV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What all manipulations have you done and insights you found?"],"metadata":{"id":"MSa1f5Uengrz"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","We are focusing on several key columns of our dataset, including 'type', 'title', 'director', 'cast', 'country', 'rating', 'listed_in', and 'description', as they contain a wealth of information.\n","By utilizing these features, we plan to create a cluster column and implement both K-means and Hierarchical clustering algorithms.\n","Additionally, we will be developing a content-based recommendation system that utilizes the information from these columns to provide personalized suggestions to users. This approach will allow us to gain valuable insights and group similar data points together, as well as provide personalized recommendations based on user preferences and viewing history."],"metadata":{"id":"LbyXE7I1olp8"}},{"cell_type":"markdown","source":["## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"],"metadata":{"id":"GF8Ens_Soomf"}},{"cell_type":"markdown","source":["#### **EDA**\n","* EDA stands for Exploratory Data Analysis. It is a process of analyzing and understanding the data, which is an essential step in the data science process. The goal of EDA is to gain insights into the data, identify patterns, and discover relationships and trends. It is an iterative process that helps to identify outliers, missing values, and any other issues that may affect the analysis and modeling of the data.\n"],"metadata":{"id":"y4cprhPuZKWJ"}},{"cell_type":"markdown","source":["#### Chart - 1"],"metadata":{"id":"0wOQAZs5pc--"}},{"cell_type":"markdown","source":["# **Column: 'type'**"],"metadata":{"id":"55e3unn4cw_b"}},{"cell_type":"code","source":["# Chart - 1 visualization code\n","# number of values of different categories in 'type'\n","df['type'].value_counts()"],"metadata":{"id":"7v_ESjsspbW7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,ax = plt.subplots(1,2, figsize=(14,5))\n","\n","# barplot\n","graph = sns.countplot(x = 'type', data = df, ax=ax[0])\n","graph.set_title('Count of Values', size=20)\n","\n","# piechart\n","df['type'].value_counts().plot(kind='pie', autopct='%1.2f%%', ax=ax[1], figsize=(15,6),startangle=90)\n","plt.title('Percentage Distribution', size=20)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"tTcRFwiBZnRu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?\n"],"metadata":{"id":"K5QZ13OEpz2H"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","I have used bar chart to visualize and display categorical data. It is one of the most commonly used graphs for summarizing and comparing the frequency or count of different categories in a dataset.\n","\n","I have used Pie charts  to visualize and represent data in a circular graph, where each slice of the pie represents a different category or data point."],"metadata":{"id":"XESiWehPqBRc"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?\n"],"metadata":{"id":"lQ7QKXXCp7Bj"}},{"cell_type":"markdown","source":["Answer Here\n","\n","* Movies has more number of counts than TV Shows.\n","* 31% of the data are from TV shows, while 69% of the data are from movies."],"metadata":{"id":"C_j1G7yiqdRP"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n","\n"],"metadata":{"id":"448CDAPjqfQr"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Yes the gained insights help creating a positive business impact  such as \"The objective of this visualization was to analyze the count of value to TV shows and Movies and percentage distribution of TV shows and Movies in our dataset\".\n"],"metadata":{"id":"3cspy4FjqxJW"}},{"cell_type":"markdown","source":["#### Chart - 2"],"metadata":{"id":"KSlN3yHqYklG"}},{"cell_type":"markdown","source":["# **Column: 'title'**"],"metadata":{"id":"RJ79zULpctEl"}},{"cell_type":"code","source":["# Chart - 2 visualization code\n","# number of unique values\n","df['title'].nunique()"],"metadata":{"id":"R4YgtaqtYklH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# text documents\n","text = \" \".join(word for word in df['title'])\n","\n","# create the word cloud using WordCloud library\n","wordcloud = WordCloud(stopwords=STOPWORDS, background_color='white', min_font_size=15).generate(text)\n","\n","# plot the word cloud\n","plt.imshow(wordcloud,  interpolation='bilinear')\n","plt.show()"],"metadata":{"id":"6A_cFzVhbw_e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"t6dVpIINYklI"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","word cloud is a visual representation of text data where words are displayed in different sizes, with the size of each word indicating its frequency or importance in the given text.WordCloud library simplifies the process of creating visually appealing word clouds and aids in understanding and communicating the key information within a textual dataset."],"metadata":{"id":"5aaW0BYyYklI"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?\n"],"metadata":{"id":"ijmpgYnKYklI"}},{"cell_type":"markdown","source":["Answer Here\n","\n","* Words like 'Love', 'Christmas', 'Man', 'World', 'Life', 'Girl', and 'Story' are frequently used in the movie title column."],"metadata":{"id":"PSx9atu2YklI"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n"],"metadata":{"id":"-JiQyfWJYklI"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Yes the gained insights help creating a positive business impact  such as \"visual representation of text data where words are displayed in different sizes, with the size of each word indicating its frequency or importance in the given text in our dataset\"."],"metadata":{"id":"BcBbebzrYklV"}},{"cell_type":"markdown","source":["#### Chart - 3"],"metadata":{"id":"EM7whBJCYoAo"}},{"cell_type":"markdown","source":["# **Column: 'director'**"],"metadata":{"id":"gej7MoZfc4jL"}},{"cell_type":"code","source":["# Chart - 3 visualization code\n","print(f'number of unique directors : {df.director.nunique()}')\n","print(f'null values in the column : {df.director.isna().sum()}')"],"metadata":{"id":"t6GMdE67YoAp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Number of Movies directed by directors are : { df[df['type']=='TV Show']['director'].value_counts().sum()}\")\n","print(f\"Number of TV shows directed by directors are : { df[df['type']=='Movie']['director'].value_counts().sum()}\")"],"metadata":{"id":"b28-UJ9NdJzz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,ax = plt.subplots(1,2, figsize=(14,5))\n","\n","# top 10 directors who directed TV shows\n","tv_shows =df[df['type']=='TV Show']['director'].value_counts()[:10].plot(kind='barh', ax=ax[0])\n","tv_shows.set_title('top 10 director who directed TV Shows', size=15)\n","\n","# top 10 directors who directed Movies\n","movies = df[df['type']=='Movie']['director'].value_counts()[:10].plot(kind='barh', ax=ax[1])\n","movies.set_title('top 10 director who directed Movies', size=15)\n","\n","plt.tight_layout(pad=1.2, rect=[0, 0, 0.95, 0.95])\n","plt.show()"],"metadata":{"id":"NsVEkCEFdUfv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?\n"],"metadata":{"id":"fge-S5ZAYoAp"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","bar plots are effective for comparing and visualizing the distribution of data across different categories. The length of the bars directly represents the magnitude of the data, making it easy to compare values among categories.The first subplot shows the Top 10 directors who directed TV Shows,\" and the second subplot shows the \"Top 10 directors who directed Movies.This layout allows for a clear and straightforward representation of the data, making it easy to compare the counts of movies and TV shows directed by the directors ."],"metadata":{"id":"5dBItgRVYoAp"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?\n","\n"],"metadata":{"id":"85gYPyotYoAp"}},{"cell_type":"markdown","source":["Answer Here\n","\n","* The three shows directed by Alastair Fothergill are the highest on the data list.\n","* Both, Jan Suter and Raul Campos have directed 18 films, more than anyone else in the dataset."],"metadata":{"id":"4jstXR6OYoAp"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n","Yes the gained insights help creating a positive business impact  such as \"The objective of this visualization was to analyze the top 10 director who directed TV shows and top 10 director who directed Movies in our dataset\".\n"],"metadata":{"id":"RoGjAbkUYoAp"}},{"cell_type":"markdown","source":["Answer Here"],"metadata":{"id":"zfJ8IqMcYoAp"}},{"cell_type":"markdown","source":["#### Chart - 4"],"metadata":{"id":"4Of9eVA-YrdM"}},{"cell_type":"markdown","source":["# **Column: 'cast'**"],"metadata":{"id":"KOo4QCTGePHl"}},{"cell_type":"code","source":["# Chart - 4 visualization code\n","df['cast']"],"metadata":{"id":"irlUoxc8YrdO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# seperating actors from cast column\n","cast = df['cast'].str.split(', ', expand=True).stack()\n","\n","# top actors name who play highest role in movie/show.\n","cast.value_counts()"],"metadata":{"id":"P76l1gDEeVSU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Number of TV Shows actors: {len(df[df['type']=='TV Show']['cast'].str.split(', ',expand=True).stack().value_counts())}\")\n","print(f\"Number of Movies actors: {len(df[df['type']=='Movie']['cast'].str.split(', ', expand=True).stack().value_counts())}\")"],"metadata":{"id":"HOHd9TKAea0c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,ax = plt.subplots(1,2, figsize=(14,5))\n","\n","# seperating TV shows actor from cast column\n","top_TVshows_actor = df[df['type']=='TV Show']['cast'].str.split(', ', expand=True).stack()\n","# plotting actor who appeared in highest number of TV Show\n","a = top_TVshows_actor.value_counts().head(10).plot(kind='barh', ax=ax[0])\n","a.set_title('Top 10 TV shows actors', size=15)\n","\n","# seperating movie actor from cast column\n","top_movie_actor = df[df['type']=='Movie']['cast'].str.split(', ', expand=True).stack()\n","# plotting actor who appeared in highest number of Movie\n","b = top_movie_actor.value_counts().head(10).plot(kind='barh', ax=ax[1])\n","b.set_title('Top 10 Movie actors', size=15)\n","\n","plt.tight_layout(pad=1.2, rect=[0, 0, 0.95, 0.95])\n","plt.show()"],"metadata":{"id":"HVGWb2u_emTl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?\n","\n"],"metadata":{"id":"iky9q4vBYrdO"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Horizontal bar plots are effective for comparing and visualizing the distribution of data across different categories. The length of the bars directly represents the magnitude of the data, making it easy to compare values among categories.The first plot shows the top 10 TV show actors, and the second plot shows the top 10 movie actors. Both plots use horizontal bar charts to represent the data.\n","\n","The horizontal bar charts are effective for comparing the frequency of appearances of different actors, and the use of subplots  allows both charts to be displayed side by side for easy comparison.\n","\n"," This layout allows for a clear and straightforward representation of the data, making it easy to compare the counts of  TV shows actors and Movie actors ."],"metadata":{"id":"aJRCwT6DYrdO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?\n","\n"],"metadata":{"id":"F6T5p64dYrdO"}},{"cell_type":"markdown","source":["Answer Here\n","\n","* The majority of the roles in the movies are played by Anupam Kher, Shahrukh Khan, and Om Puri.\n","* In the shows, Takahiro Sakurai, Yuki Kaji, and Daisuke Ono played the most number of roles."],"metadata":{"id":"Xx8WAJvtYrdO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n"],"metadata":{"id":"y-Ehk30pYrdP"}},{"cell_type":"markdown","source":["Answer Here\n","\n","\n","Yes the gained insights help creating a positive business impact  such as \"The objective of this visualization was to analyze the top 10 TV shows actors and top 10 movie actors in our dataset\"."],"metadata":{"id":"jLNxxz7MYrdP"}},{"cell_type":"markdown","source":["#### Chart - 5"],"metadata":{"id":"bamQiAODYuh1"}},{"cell_type":"markdown","source":["# **Column: 'country'**"],"metadata":{"id":"eABQ5n8Xe-aX"}},{"cell_type":"code","source":["# Chart - 5 visualization code\n","# number of unique values\n","df['country'].nunique()"],"metadata":{"id":"TIJwrbroYuh3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,ax = plt.subplots(1,2, figsize=(15,5))\n","plt.suptitle('Top 10 country with the highest number of movie/shows', weight='bold', size=15, y=1.01)\n","\n","# univariate analysis\n","df['country'].value_counts().nlargest(10).plot(kind='barh', ax=ax[0])\n","\n","# bivariate analysis\n","graph = sns.countplot(x=\"country\", data=df, hue='type', order=df['country'].value_counts().index[0:10], ax=ax[1])\n","plt.xticks(rotation=90)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"RnbiY1OmfCvR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?\n","\n"],"metadata":{"id":"QHF8YVU7Yuh3"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Horizontal bar plots are effective for comparing and visualizing the distribution of data across different categories. The length of the bars directly represents the magnitude of the data, making it easy to compare values among categories.It is used to display the top 10 countries with the highest number of movies and TV shows available on Netflix. This layout allows for a clear and straightforward representation of the data, making it easy to compare the counts of movies and TV shows for each country.\n","\n","We use a Grouped Bar Plot (Countplot) to visually compare the frequency or count of different categories in a dataset. This type of plot is particularly useful when we want to observe how two categorical variables interact and how their counts vary across different levels of each category.Grouped Bar Plots (Countplots) are valuable visualization tools for comparing and exploring the relationships between categorical variables, making them an essential part of exploratory data analysis and data visualization tasks."],"metadata":{"id":"dcxuIMRPYuh3"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?\n","\n"],"metadata":{"id":"GwzvFGzlYuh3"}},{"cell_type":"markdown","source":["Answer Here\n","\n","* The United States-based movies and TV shows were produced most, followed by India and the United Kingdom.\n","* In India and United State, a greater number of movies are present compared to TV shows.\n","* In the UK, Japan, and South Korea there are a greater number of TV shows than movies."],"metadata":{"id":"uyqkiB8YYuh3"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n"],"metadata":{"id":"qYpmQ266Yuh3"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Yes the gained insights help creating a positive business impact  such as \"The objective of this visualization was to analyze the top 10 country with the highest number of Movies and TV shows  in our dataset\"."],"metadata":{"id":"_WtzZ_hCYuh4"}},{"cell_type":"markdown","source":["#### Chart - 6"],"metadata":{"id":"OH-pJp9IphqM"}},{"cell_type":"markdown","source":["# ** Column: 'release_year'**"],"metadata":{"id":"C6wzkxLJmLAm"}},{"cell_type":"code","source":["# Chart - 6 visualization code\n","# number of unique values\n","df['release_year'].nunique()"],"metadata":{"id":"kuRf4wtuphqN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"rQZzJhgKmQpI"}},{"cell_type":"code","source":["print(f'Oldest release year : {df.release_year.min()}')\n","print(f'Latest release year : {df.release_year.max()}')"],"metadata":{"id":"JnTJSAfGmTVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,ax = plt.subplots(1,2, figsize=(15,6))\n","\n","# Univariate analysis\n","hist = sns.histplot(df['release_year'], ax=ax[0])\n","hist.set_title('Distribution by released year', size=15)\n","\n","# Bivariate analysis\n","count = sns.countplot(x=\"release_year\", hue='type', data=df, order=df['release_year'].value_counts().index[0:15], ax=ax[1])\n","count.set_title('Movie/TV shows released in top 15 year', size=15)\n","plt.xticks(rotation=90)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"uiq38VJAmYqg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?\n","\n"],"metadata":{"id":"bbFf2-_FphqN"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","The first graph  is a univariate analysis plot, specifically a histogram, showing the distribution of the \"release_year\" variable from the dataset. The histogram displays the frequency distribution of release years, giving an overview of how many movies or TV shows were released in different years.\n","\n","The second graph is a bivariate analysis plot, specifically a count plot, showing the count of movies and TV shows released in the top 15 years with the highest frequencies. The bars are grouped by the \"type\" variable, which distinguishes between movies and TV shows, and the count of each type is shown for the top 15 years.\n","\n","We use a Grouped Bar Plot (Countplot) to visually compare the frequency or count of different categories in a dataset. This type of plot is particularly useful when we want to observe how two categorical variables interact and how their counts vary across different levels of each category.Grouped Bar Plots (Countplots) are valuable visualization tools for comparing and exploring the relationships between categorical variables, making them an essential part of exploratory data analysis and data visualization tasks."],"metadata":{"id":"loh7H2nzphqN"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?\n","\n"],"metadata":{"id":"_ouA3fa0phqN"}},{"cell_type":"markdown","source":["Answer Here\n","\n","* Netflix starts releasing more Movies/TV shows in recent years compared to old ones.\n","* Most Movies and TV shows are available on Netflix between 2015 and 2020, and the highest are in 2018."],"metadata":{"id":"VECbqPI7phqN"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n"],"metadata":{"id":"Seke61FWphqN"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Yes the gained insights help creating a positive business impact  such as \"The objective of this visualization was to analyze the distribution by released year and Movie/TV shows released in Top 15 years in our dataset\"."],"metadata":{"id":"DW4_bGpfphqN"}},{"cell_type":"markdown","source":["#### Chart - 7"],"metadata":{"id":"PIIx-8_IphqN"}},{"cell_type":"markdown","source":["# **Column: 'rating'**"],"metadata":{"id":"r8-BUt9fnvu0"}},{"cell_type":"code","source":["# Chart - 7 visualization code\n","fig,ax = plt.subplots(1,2, figsize=(15,6))\n","plt.suptitle('Top 10 rating given for movie and shows', weight='bold', y=1.02, size=15)\n","\n","# univariate analysis\n","sns.countplot(x=\"rating\", data=df, order=df['rating'].value_counts().index[0:10], ax=ax[0])\n","\n","# bivariate analysis\n","graph = sns.countplot(x=\"rating\", data=df, hue='type', order=df['rating'].value_counts().index[0:10], ax=ax[1])\n","plt.xticks(rotation=90)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"lqAIGUfyphqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?\n","\n"],"metadata":{"id":"t27r6nlMphqO"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Univariate Analysis:\n","The first graph  is a \"Countplot\" representing the frequency of each rating category for movies and TV shows in the dataset. The x-axis displays the \"rating\" categories, and the y-axis shows the count of occurrences for each rating. The order of the x-axis labels is set to display the top 10 most frequently occurring rating categories.\n","\n","Bivariate Analysis:\n","The second graph  is another \"Countplot\" representing the frequency of each rating category for movies and TV shows, differentiated by the \"type\" of content. The x-axis displays the \"rating\" categories, and the y-axis shows the count of occurrences for each rating. The bars are further distinguished by color to represent movies and TV shows separately. Again, the order of the x-axis labels is set to display the top 10 most frequently occurring rating categories.\n","\n","We use a Grouped Bar Plot (Countplot) to visually compare the frequency or count of different categories in a dataset. This type of plot is particularly useful when we want to observe how two categorical variables interact and how their counts vary across different levels of each category.Grouped Bar Plots (Countplots) are valuable visualization tools for comparing and exploring the relationships between categorical variables, making them an essential part of exploratory data analysis and data visualization tasks."],"metadata":{"id":"iv6ro40sphqO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?\n","\n"],"metadata":{"id":"r2jJGEOYphqO"}},{"cell_type":"markdown","source":["Answer Here\n","\n","* The majority of Movies and TV shows have a rating of TV-MA, which stands for \"Mature Audience,\" followed by TV-14, which stands for \"Younger Audience.\"\n","* When compared to TV shows, Movies receive the highest rating, which is pretty obvious given that a number of Movies are higher compared to TV shows, as we saw earlier in the type column."],"metadata":{"id":"Po6ZPi4hphqO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n"],"metadata":{"id":"b0JNsNcRphqO"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Yes the gained insights help creating a positive business impact  such as \"The objective of this visualization was to analyze the top 10 rating given for Movie and TV shows  in our dataset\"."],"metadata":{"id":"xvSq8iUTphqO"}},{"cell_type":"markdown","source":["#### Chart - 8"],"metadata":{"id":"BZR9WyysphqO"}},{"cell_type":"markdown","source":["# **Column: 'listed_in'**"],"metadata":{"id":"LRwUqznjsE4v"}},{"cell_type":"markdown","source":["Because this column is a genre column, in order to count the genres, we must separate them."],"metadata":{"id":"HyOJj7S7sOwg"}},{"cell_type":"code","source":["# Chart - 8 visualization code\n","# seperating genre from listed_in columns for analysis purpose\n","genres = df['listed_in'].str.split(', ', expand=True).stack()\n","\n","# top 10 genres in listed movies/TV shows\n","genres = genres.value_counts().reset_index().rename(columns={'index':'genre', 0:'count'})\n","genres.head()"],"metadata":{"id":"TdPTWpAVphqO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# number of genres present in dataset\n","len(genres)"],"metadata":{"id":"OFRc-oUfsTHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plotting graph\n","fig,ax = plt.subplots(1,2, figsize=(15,6))\n","\n","# Top 10 genres\n","top = sns.barplot(x='genre', y = 'count', data=genres[:10], ax=ax[0])\n","top.set_title('Top 10 genres present in Netflix', size=20)\n","plt.setp(top.get_xticklabels(), rotation=90)\n","\n","# Last 10 genres\n","bottom = sns.barplot(x='genre', y = 'count', data=genres[-10:], ax=ax[1])\n","bottom.set_title('Last 10 genres present in Netflix', size=20)\n","plt.xticks(rotation=90)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"FczYFj_3sVrf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?\n","\n"],"metadata":{"id":"jj7wYXLtphqO"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","The chart on the left  represents the top 10 genres present in Netflix, while the chart on the right represents the last 10 genres. The y-axis represents the count of each genre, and the x-axis shows the genre names. The bars' height indicates the count of each genre, allowing for easy comparison between the top and last genres.\n","\n","The visualization is created using the seaborn library in Python, which provides a high-level interface for drawing attractive statistical graphics.\n","\n","We use a Grouped Bar Plot to visually compare the frequency or count of different categories in a dataset. This type of plot is particularly useful when we want to observe how two categorical variables interact and how their counts vary across different levels of each category.Grouped Bar Plots (Countplots) are valuable visualization tools for comparing and exploring the relationships between categorical variables, making them an essential part of exploratory data analysis and data visualization tasks."],"metadata":{"id":"Ob8u6rCTphqO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?\n","\n"],"metadata":{"id":"eZrbJ2SmphqO"}},{"cell_type":"markdown","source":["Answer Here\n","\n","* International Movies, Dramas, and Comedies make up the majority of the genres.\n","* TV Shows, Classic and cult TV, TV thrillers, Stand-Up comedy, and Talk shows account for the least genres."],"metadata":{"id":"mZtgC_hjphqO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n"],"metadata":{"id":"rFu4xreNphqO"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Yes the gained insights help creating a positive business impact such as \"The objective of this visualization was to analyze the top 10 genres present in Netflix and last 10 genres present in Netflix  given for Movie and TV shows in our dataset\"."],"metadata":{"id":"ey_0qi68phqO"}},{"cell_type":"markdown","source":["Chart - 9"],"metadata":{"id":"7601bkIStqny"}},{"cell_type":"markdown","source":["# Column: 'description'*"],"metadata":{"id":"aixasv9Au7g_"}},{"cell_type":"code","source":["# Chart - 9 visualization code\n","# text documents\n","text = \" \".join(word for word in df['description'])\n","\n","# create the word cloud using WordCloud library\n","wordcloud = WordCloud(stopwords=STOPWORDS, background_color='white', min_font_size=15).generate(text)\n","\n","# plot the word cloud\n","plt.imshow(wordcloud,  interpolation='bilinear')\n","plt.show()"],"metadata":{"id":"B2aS4O1ophqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?\n","\n"],"metadata":{"id":"gCFgpxoyphqP"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Here. word cloud is a visual representation of text data where words are displayed in different sizes, with the size of each word indicating its frequency or importance in the given text.WordCloud library simplifies the process of creating visually appealing word clouds and aids in understanding and communicating the key information within a textual dataset."],"metadata":{"id":"TVxDimi2phqP"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?\n","\n"],"metadata":{"id":"OVtJsKN_phqQ"}},{"cell_type":"markdown","source":["Answer Here\n","\n","* The most frequently used words in the description column are \"family,\" \"find,\" \"life,\" \"love,\" \"new world,\" and \"friend.\""],"metadata":{"id":"ngGi97qjphqQ"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n"],"metadata":{"id":"lssrdh5qphqQ"}},{"cell_type":"markdown","source":["Answer Here\n","\n","\n","Yes the gained insights help creating a positive business impact such as \"visual representation of text data where words are displayed in different sizes, with the size of each word indicating its frequency or importance in the given text in our dataset\"."],"metadata":{"id":"tBpY5ekJphqQ"}},{"cell_type":"markdown","source":["#### Chart - 10"],"metadata":{"id":"U2RJ9gkRphqQ"}},{"cell_type":"markdown","source":["# ** Data Cleaning**\n","\n","#### **What is data cleaning?**\n","* Data cleaning is the process of identifying and correcting or removing inaccuracies, inconsistencies, and missing values in a dataset. It is an important step in the data preparation process that ensures that the data is accurate, complete, and in a format that can be easily analyzed. Data cleaning may include tasks such as removing duplicate records, filling in missing values, correcting errors, and standardizing data formats. The goal of data cleaning is to improve the quality of the data and make it suitable for further analysis and modeling."],"metadata":{"id":"R4RaX78svkoK"}},{"cell_type":"markdown","source":["**Duplicate Values**\n","\n"],"metadata":{"id":"J9ZnzoECvxTR"}},{"cell_type":"code","source":["# counting duplicate values\n","df.duplicated().sum()"],"metadata":{"id":"T1kYrz0uv06R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Missing Values**"],"metadata":{"id":"uxA8v-u7v548"}},{"cell_type":"code","source":["# Missing Values/Null Values Count\n","print(df.isnull().sum())"],"metadata":{"id":"yGtgETtnv_yi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Chart - 10 visualization code\n","# Visualizing the missing values\n","import missingno as msno\n","msno.bar(df, color='green',sort='ascending', figsize=(10,3), fontsize=15)"],"metadata":{"id":"GM7a4YP4phqQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Missing Values Percentage\n","round(df.isna().sum()/len(df)*100, 2)"],"metadata":{"id":"gJ6sOnyiwJ_W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Handling Missing Values**\n","* The \"empty string\" can be used to replace the missing values in the director, cast, and country attributes.\n","* There is a small percentage of null values in the rating and date_added columns; eliminating these nan values will have little effect on the model's construction. As a result, the nan value in the rating and date_added columns is simply removed."],"metadata":{"id":"i4g32J0IwPhO"}},{"cell_type":"code","source":["# Handling Missing Values & Missing Value Imputation\n","df[['director','cast','country']] = df[['director','cast','country']].fillna(' ')\n","df.dropna(axis=0, inplace=True)"],"metadata":{"id":"20z1qbd-wT_F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# checking for null values after treating them.\n","df.isna().sum()"],"metadata":{"id":"_Yp5UlgjwZ1u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?\n","\n","\n","\n"],"metadata":{"id":"1M8mcRywphqQ"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","The graph created using the missingno.bar() function from the missingno library is called a \"Missing Value Bar Chart.\"\n","\n","This chart is used to visualize the missing values in a dataset. It provides a concise summary of the missingness patterns across different variables (columns) in the dataframe.\n","The missing value bar chart is a quick and effective way to identify missing values in the dataset visually. By looking at the chart, you can get an overview of the completeness of the data and see which variables have more missing data.\n","It helps in identifying patterns of missingness across different columns, which can be valuable in understanding if there are systematic reasons for missing data."],"metadata":{"id":"8agQvks0phqQ"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"tgIPom80phqQ"}},{"cell_type":"markdown","source":["Answer Here\n","\n","It provides a concise summary of the missingness patterns across different variables (columns) in the dataframe\"."],"metadata":{"id":"Qp13pnNzphqQ"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"JMzcOPDDphqR"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Yes the gained insights help creating a positive business impact such as \"The objective of this visualization was to visualize the missing values in a dataset. It provides a concise summary of the missingness patterns across different variables (columns) in the dataframe\"."],"metadata":{"id":"R4Ka1PC2phqR"}},{"cell_type":"markdown","source":["#### Chart - 11"],"metadata":{"id":"x-EpHcCOp1ci"}},{"cell_type":"markdown","source":["# **Handling Outliers**"],"metadata":{"id":"6eY8wj2_0EMp"}},{"cell_type":"code","source":["# Chart - 11 visualization code\n","\n","# Handling Outliers & Outlier treatments\n","\n","# plotting graph\n","fig,ax = plt.subplots(1,2, figsize=(15,5))\n","\n","# Display boxplot and dist plot.\n","sns.distplot(x=df['release_year'], ax=ax[0])\n","sns.boxplot(data=df, ax=ax[1])"],"metadata":{"id":"mAQTIvtqp1cj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"X_VqEhTip1ck"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Distribution Plot:\n","The distribution plot (sns.distplot()) is used to visualize the distribution of a continuous variable, in this case, the 'release_year' feature of the dataset. It displays the frequency distribution of the data points, giving an overview of how the values are spread over the range of the variable. The curve in the distribution plot represents the probability density function (PDF) of the data. This plot is useful for understanding the central tendency, skewness, and presence of outliers in the 'release_year' feature.\n","\n","Box Plot:\n","The box plot (sns.boxplot()) is another type of visualization used to display the distribution of data and to detect outliers. It shows the distribution of data based on the quartiles, specifically the median, interquartile range (IQR), and any potential outliers. The box in the plot represents the IQR (from the 25th percentile to the 75th percentile), and the whiskers extend to the minimum and maximum values within 1.5 times the IQR. Any data points that fall outside the whiskers are considered outliers and are represented as individual points."],"metadata":{"id":"-vsMzt_np1ck"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"8zGJKyg5p1ck"}},{"cell_type":"markdown","source":["Answer Here\n","\n","* Except for the release year, almost all of the data are presented in text format.\n","* The textual format contains the data we need to build a cluster/building model. Therefore, there is no need to handle outliers."],"metadata":{"id":"ZYdMsrqVp1ck"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"PVzmfK_Ep1ck"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Yes the gained insights help creating a positive business impact as these plots are helpful for identifying the presence of outliers in the 'release_year' feature. Outliers are data points that significantly deviate from the majority of the data and may indicate errors, data quality issues, or unusual observations. By visualizing the distribution and using the box plot, data analysts can make informed decisions about how to handle outliers, such as removing them or applying outlier treatments to ensure that the data is suitable for further analysis or modeling."],"metadata":{"id":"druuKYZpp1ck"}},{"cell_type":"markdown","source":["#### Chart - 12"],"metadata":{"id":"n3dbpmDWp1ck"}},{"cell_type":"markdown","source":["# Textual Data **Preprocessing**"],"metadata":{"id":"lI4skQYC1TFe"}},{"cell_type":"markdown","source":["**What is textual data preprocessing?**\n","\n","* Textual data preprocessing is the process of preparing text data for analysis or modeling. It includes a series of steps that are applied to raw text data in order to clean, organize and standardize it so that it can be easily analyzed or used as input for natural language processing or machine learning models. The preprocessing steps typically include tokenization, stop-word removal, stemming or lemmatization, lowercasing, removing punctuation, and removing numbers. The goal of textual data preprocessing is to prepare the data for further analysis and modeling by removing irrelevant information and standardizing the format of the text. This can help improve the accuracy and effectiveness of the analysis or modeling."],"metadata":{"id":"sb8-6RkH1YmS"}},{"cell_type":"markdown","source":["**Modeling Approach**\n","\n","\n","1.   Choose the attributes that you want to cluster.\n","2.   Text Preprocessing: Change all textual data to lowercase and eliminate all punctuation marks and stopwords. Removing commonly occurring words such as \"the\", \"and\", \"a\", etc. that don't carry much meaning.\n","3.   Stemming or Lemmatization: Normalizing the words by reducing them to their base form.\n","4.   Tokenization: Breaking the text into smaller units, such as sentences or words.\n","5.   Dimensionality reduction.\n","6.   Make use of various algorithms to cluster the movies and various techniques to determine the optimal number of clusters.\n","7.   Build the optimal number of clusters and use wordclouds to display the contents of each cluster."],"metadata":{"id":"IaM_-G1x1fFU"}},{"cell_type":"markdown","source":["# **Selecting Attributes**"],"metadata":{"id":"fNWPxLnD1lTv"}},{"cell_type":"code","source":["df.head(3)"],"metadata":{"id":"kn4tXlEX1wIi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We will cluster the Netflix movies and TV shows into groups based on the following textual characteristics:\n","\n","* Director\n","* Cast\n","* Country\n","* Rating\n","* Listed in (genres)\n","* Description"],"metadata":{"id":"rYIMvd941qzg"}},{"cell_type":"code","source":["# creating tags column using all text column which one is used for model building purpose.\n","df['text_data'] = df['director'] + df['cast'] + df['country'] + \\\n","                     df['rating'] + df['listed_in'] + df['description']"],"metadata":{"id":"DaC61G_211iH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# checking the first row\n","df['text_data'][0]"],"metadata":{"id":"AVdb7Hc91_h2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* We were able to successfully consolidate all of the required data into a single column."],"metadata":{"id":"pdrcIn7Z2GpJ"}},{"cell_type":"markdown","source":["# **Removing Stop words and Lower Casing.**"],"metadata":{"id":"-g-ZQN8N2LIf"}},{"cell_type":"markdown","source":["In natural language processing (NLP) tasks, removing stop words and lowercasing words are common pre-processing steps.\n","\n","* **Stop words Removal:**  Words such as \"a,\" \"an,\" \"the,\" and \"is,\" are words that are commonly used in a language but do not convey much meaning. These words can add noise to the data and can sometimes affect the performance of NLP models, so they are often removed as a pre-processing step.\n","\n","* **Lowercasing:** It is the process of converting all the words in a text to lowercase. This can be useful in tasks such as information retrieval or text classification where case differences are not important and also can reduce the size of the vocabulary making it easier to work with larger texts or texts in languages with a high number of inflected forms."],"metadata":{"id":"puTIafjW2Qj5"}},{"cell_type":"code","source":["# create a set of English stop words\n","stop_words = stopwords.words('english')\n","\n","# displaying stopwords\n","np.array(stop_words)"],"metadata":{"id":"ScRLYrHr2VIG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def stopwords(text):\n","    '''a function for removing the stopword and lowercase the each word'''\n","    text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n","    # joining the list of words with space separator\n","    return \" \".join(text)\n"],"metadata":{"id":"3BmIKRoW2Yo0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# applying stopwords function.\n","df['text_data'] = df['text_data'].apply(stopwords)"],"metadata":{"id":"BE99TcX-2cxW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# checking the first row again\n","df['text_data'][0]"],"metadata":{"id":"mJacgExe2g6T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* We have successfully changed the corpus to lowercase and removed all stopwords."],"metadata":{"id":"K82vfXLi2lOd"}},{"cell_type":"markdown","source":["# **Removing Punctuations**"],"metadata":{"id":"IElxajV92pKS"}},{"cell_type":"markdown","source":["Removing punctuation is the process of removing any punctuation marks (e.g., periods, commas, exclamation points, etc.) from text data. This is a common pre-processing step in natural language processing (NLP) tasks and text analysis, as punctuation marks often do not carry much meaning and can add noise to the data. Removing punctuation can also make it easier to tokenize text into words or sentences, as punctuation marks often act as delimiters between words or sentences. Additionally, removing punctuation can also help in reducing the size of the vocabulary, which can make it easier to work with larger texts or texts in languages with a high number of inflected forms. It can be done using python libraries such as string, re, and nltk."],"metadata":{"id":"zPJvfpta2rgK"}},{"cell_type":"code","source":["# function to remove punctuations\n","\n","def remove_punctuation(text):\n","    '''a function for removing punctuation'''\n","    import string\n","    # replacing the punctuations with no space, which in effect deletes the punctuation marks.\n","    translator = str.maketrans('', '', string.punctuation)\n","    # return the text stripped of punctuation marks\n","    return text.translate(translator)"],"metadata":{"id":"n3zPb83l2x1h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# applying remove_punctuation function\n","df['text_data'] = df['text_data'].apply(remove_punctuation)"],"metadata":{"id":"OlxHpLFb21FD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# checking the first row after the process\n","df['text_data'][0]"],"metadata":{"id":"yZkDVHr121vf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* We have effectively eliminate all the punctuation marks from the corpus."],"metadata":{"id":"wc8t39_Q29NI"}},{"cell_type":"markdown","source":["# ** Stemming**"],"metadata":{"id":"yf3x7Wym2_v4"}},{"cell_type":"markdown","source":["Stemming is the process of reducing a word to its base or root form. This is a common pre-processing step in natural language processing (NLP) tasks and text analysis. The goal of stemming is to reduce words to their base form so that words with the same stem are treated as the same word, even if they are written in different forms. For example, stemming would reduce \"running,\" \"runner,\" and \"ran\" to the base form \"run.\" This can be useful in tasks such as information retrieval or text classification where the specific form of a word is not important, and it can also help in reducing the size of the vocabulary. There are several stemmers available in python such as Porter stemmer, Snowball stemmer and Lancaster stemmer.\n","\n","* We will utilize **SnowballStemmer** to construct a meaningful word from a word corpus."],"metadata":{"id":"6kI2JMmf3GP5"}},{"cell_type":"code","source":["# create an object of stemming function\n","stemmer = SnowballStemmer(\"english\")\n","\n","# define a function to apply stemming using SnowballStemmer\n","def stemming(text):\n","    '''a function which stems each word in the given text'''\n","    text = [stemmer.stem(word) for word in text.split()]\n","    return \" \".join(text)"],"metadata":{"id":"3dpAqs8K3H5X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# appying stemming function\n","df['text_data'] = df['text_data'].apply(stemming)"],"metadata":{"id":"ZFr8SlhQ3LsK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# checking the first row after the process\n","df['text_data'][0]"],"metadata":{"id":"LIvj05bC3OvF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* We have successfully utilized the stemming process."],"metadata":{"id":"s0_vIS083SMN"}},{"cell_type":"markdown","source":["# **Text Vectorization**"],"metadata":{"id":"DyXMgp_v3Txz"}},{"cell_type":"markdown","source":["Text vectorization is the process of converting text data into numerical vectors or feature representations that can be used for machine learning or data analysis tasks. In simple terms, it transforms the text data into numerical data which can be easily processed by machine learning algorithms. There are several text vectorization techniques available such as bag of words, Tf-idf, Word2vec, and GloVe etc.\n","\n","* We will be using the TF-IDF vectorizer, which stands for Term Frequency Inverse Document Frequency\n","* TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document). The more often a word appears in a document, the higher its TF score.\n","* IDF(t) = IDF measures how rare a word is across all the documents in the corpus. The rarer a word, the higher its IDF score.\n","* The product of TF and IDF is used to calculate the overall weight of a word in a document, which is known as the TF-IDF score. Words with high TF-IDF scores are considered to be more important and relevant to the document than words with low TF-IDF scores."],"metadata":{"id":"7K3PrD_f3XWo"}},{"cell_type":"code","source":["# create the object of tfid vectorizer\n","tfidf = TfidfVectorizer(stop_words='english', lowercase=False, max_features = 10000)   # max features = 10000 to prevent system from crashing\n","\n","# fit the vectorizer using the text data\n","tfidf.fit(df['text_data'])\n","\n","# collect the vocabulary items used in the vectorizer\n","dictionary = tfidf.vocabulary_.items()"],"metadata":{"id":"RYv-PRVB3cO5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(dictionary)) #number of independet features created from \"text_data\" columns"],"metadata":{"id":"6Ipok65_3iWx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert vector into array form for clustering\n","vector = tfidf.transform(df['text_data']).toarray()\n","\n","# summarize encoded vector\n","print(vector)\n","print(f'shape of the vector : {vector.shape}')\n","print(f'datatype : {type(vector)}')"],"metadata":{"id":"8cHY5U2I3lH_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Dimensionality Reduction**"],"metadata":{"id":"fGfTjjb13rST"}},{"cell_type":"markdown","source":["Dimensionality reduction is the process of reducing the number of features or dimensions in a dataset while retaining as much information as possible. The main goal of dimensionality reduction is to simplify the data while minimizing the loss of information. It is a crucial step in machine learning and data analysis as it can help to improve the performance of models, reduce overfitting, and make it easier to visualize and interpret the data.\n","\n","* There are several techniques used for dimensionality reduction, such as:\n","Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), t-Distributed Stochastic Neighbor Embedding (t-SNE), Autoencoder, and Random Projection etc.\n","* We will use Principal Component Analysis (PCA) to reduce the dimensionality of data."],"metadata":{"id":"xu78lRCl3vEa"}},{"cell_type":"code","source":["# using PCA to reduce dimensionality\n","pca = PCA(random_state=42)\n","pca.fit(vector)"],"metadata":{"id":"0AVhg4Rn44Hw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Explained variance for different number of components\n","plt.figure(figsize=(10,5))\n","plt.plot(np.cumsum(pca.explained_variance_ratio_))\n","plt.title('PCA - Cumulative explained variance vs Number of components')\n","plt.xlabel('Number of components')\n","plt.ylabel('Cumulative explained variance')\n","plt.axhline(y= 0.8, color='red', linestyle='--')\n","plt.axvline(x= 3000, color='green', linestyle='--')\n","plt.show()"],"metadata":{"id":"WPbnN8RU6YVv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"ylSl6qgtp1ck"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","I have used the line plot because the graph helps in making informed decisions on how many principal components to keep for an optimal trade-off between dimensionality reduction and information preservation in the data."],"metadata":{"id":"m2xqNkiQp1ck"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"ZWILFDl5p1ck"}},{"cell_type":"markdown","source":["Answer Here\n","\n","* We discover that approximately 7500 components account for 100 percent of the variance.\n","* 3000 components alone account for more than 80% of the variance.\n","* Therefore, we can take the top 3000 components to reduce dimensionality and simplify the model while still being able to capture more than 80% of the variance."],"metadata":{"id":"x-lUsV2mp1ck"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"M7G43BXep1ck"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Yes the gained insights help creating a positive business impact as the graph helps in making informed decisions on how many principal components to keep for an optimal trade-off between dimensionality reduction and information preservation in the data."],"metadata":{"id":"5wwDJXsLp1cl"}},{"cell_type":"code","source":["# reducing the dimensions to 3000 using pca\n","pca = PCA(n_components=3000, random_state=42)\n","pca.fit(vector)"],"metadata":{"id":"Ue7Vve1W5FmR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# transformed features\n","X = pca.transform(vector)\n","\n","# shape of transformed vectors\n","X.shape"],"metadata":{"id":"V5dOj_Ag5LEv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 13"],"metadata":{"id":"Ag9LCva-p1cl"}},{"cell_type":"markdown","source":["# **Model Implementation**"],"metadata":{"id":"tYLjHb415R-x"}},{"cell_type":"markdown","source":["# **K-Means Clustering**\n","\n","K-means clustering is a popular unsupervised machine learning technique used to group similar data points together. The goal of k-means clustering is to partition a dataset into k clusters, where each cluster contains similar data points and is represented by its centroid.\n","\n","The k-means algorithm works by first randomly selecting k centroids, one for each cluster. Then, it assigns each data point to the cluster whose centroid is closest to it. This process is repeated until the assignment of data points to clusters no longer changes, or until a maximum number of iterations is reached.\n","\n","* We will determine the best number of clusters for the K-means clustering algorithm by visualizing the elbow curve and silhouette score."],"metadata":{"id":"J9RM6WP-5Tve"}},{"cell_type":"code","source":["# Chart - 13 visualization code\n","\n","'''Elbow method to find the optimal value of K'''\n","\n","# Initialize a list to store the sum of squared errors for each value of K\n","SSE = []\n","\n","for k in range(1, 16):\n","  # Initialize the k-means model with the current value of K\n","  kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n","  # Fit the model to the data\n","  kmeans.fit(X)\n","  # Compute the sum of squared errors for the model\n","  SSE.append(kmeans.inertia_)\n","\n","# Plot the values of SSE\n","plt.plot(range(1, 16), SSE)\n","plt.title('The Elbow Method - KMeans clustering')\n","plt.xlabel('Number of clusters')\n","plt.ylabel('Sum of squared errors')\n","plt.show()"],"metadata":{"id":"EUfxeq9-p1cl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''Silhouette score method to find the optimal value of k'''\n","\n","# Initialize a list to store the silhouette score for each value of k\n","silhouette_avg = []\n","\n","for k in range(2, 16):\n","  # Initialize the k-means model with the current value of k\n","  kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n","  # Fit the model to the data\n","  kmeans.fit(X)\n","  # Predict the cluster labels for each point in the data\n","  labels = kmeans.labels_\n","  # Compute the silhouette score for the model\n","  score = silhouette_score(X, labels)\n","  silhouette_avg.append(score)\n","\n","# Plot the Silhouette analysis\n","plt.plot(range(2,16), silhouette_avg)\n","plt.xlabel('Number of clusters')\n","plt.ylabel('Silhouette score')\n","plt.title('Silhouette analysis For Optimal k - KMeans clustering')\n","plt.show()"],"metadata":{"id":"LhV2PG4R6oi1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Clustering the data into 6 clusters\n","kmeans = KMeans(n_clusters=6, init='k-means++', random_state=33)\n","kmeans.fit(X)"],"metadata":{"id":"V4vEEfdl6yth"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluation metrics - distortion, Silhouette score\n","kmeans_distortion = kmeans.inertia_\n","kmeans_silhouette_score = silhouette_score(X, kmeans.labels_)\n","\n","print((kmeans_distortion, kmeans_silhouette_score))"],"metadata":{"id":"ofXdXIhD60nJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Adding a kmeans cluster number attribute\n","netflix_df['kmeans_cluster'] = kmeans.labels_"],"metadata":{"id":"qj1yW1kE62Oa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Number of movies and tv shows in each cluster\n","plt.figure(figsize=(8,5))\n","graph = sns.countplot(x='kmeans_cluster',data=netflix_df, hue='type')\n","plt.title('Number of movies and TV shows in each cluster - Kmeans Clustering')\n","\n","# adding value count on the top of bar\n","for p in graph.patches:\n","  graph.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))"],"metadata":{"id":"M_pwLINm62t4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Building wordclouds for different clusters in K-Means Clustering**"],"metadata":{"id":"Vj1P0cY668ey"}},{"cell_type":"code","source":["def kmeans_worldcloud(cluster_number, column_name):\n","\n","  '''function for Building a wordcloud for the movie/shows'''\n","\n","  df_wordcloud = df[['kmeans_cluster',column_name]].dropna()\n","  df_wordcloud = df_wordcloud[df_wordcloud['kmeans_cluster']==cluster_number]\n","\n","  # text documents\n","  text = \" \".join(word for word in df_wordcloud[column_name])\n","\n","  # create the word cloud\n","  wordcloud = WordCloud(stopwords=set(STOPWORDS), background_color=\"white\").generate(text)\n","\n","  # Generate a word cloud image\n","  plt.imshow(wordcloud, interpolation='bilinear')\n","  plt.axis(\"off\")\n","  plt.show()"],"metadata":{"id":"Qu2VHXPX6_2D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Word Cloud on \"description\" column for different cluster ##\n","for i in range(6):\n","  print(f'cluster {i}')\n","  kmeans_worldcloud(i,'description')"],"metadata":{"id":"NGgEUNvo7Qrg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Word Cloud on \"cast\" column for different cluster ##\n","for i in range(6):\n","  print(f'cluster {i}')\n","  kmeans_worldcloud(i,'cast')"],"metadata":{"id":"m71M95Aj7ZsT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Word Cloud on \"director\" column for different cluster ##\n","for i in range(6):\n","  print(f'cluster {i}')\n","  kmeans_worldcloud(i,'director')"],"metadata":{"id":"76VzOUdv7s1O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Word Cloud on \"listed_in\" (genre) col for different cluster ##\n","for i in range(6):\n","  print(f'cluster {i}')\n","  kmeans_worldcloud(i,'listed_in')"],"metadata":{"id":"Q_wImc147xIn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Word Cloud on \"country\" column column for different cluster ##\n","for i in range(6):\n","  print(f'cluster {i}')\n","  kmeans_worldcloud(i,'country')"],"metadata":{"id":"Kb2Zm52e72mB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##Word Cloud on \"title\" column column for different cluster ##\n","for i in range(6):\n","  print(f'cluster {i}')\n","  kmeans_worldcloud(i,'title')"],"metadata":{"id":"JfBbW3pX7-tT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"E6MkPsBcp1cl"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","The Elbow Method plot is a technique used to determine the optimal value of K (the number of clusters) for K-means clustering. K-means is an unsupervised machine learning algorithm used for clustering data points into K distinct clusters.\n","In the plot, the \"elbow\" point is where the SSE starts to level off. The optimal value of K is usually chosen as the value corresponding to the \"elbow\" point on the graph, as it provides a good trade-off between capturing the data structure with an adequate number of clusters. However, the Elbow Method is not always definitive, and other evaluation methods may also be considered for finalizing the optimal value of K."],"metadata":{"id":"V22bRsFWp1cl"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"2cELzS2fp1cl"}},{"cell_type":"markdown","source":["Answer Here\n","\n","* The sum of squared distance between each point and the centroid in a cluster decreases with the increase in the number of clusters.\n","* The highest Silhouette score is obtained for 6 clusters.\n","* Building 6 clusters using the k-means clustering algorithm."],"metadata":{"id":"ozQPc2_Ip1cl"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"3MPXvC8up1cl"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Yes the gained insights help creating a positive business impact"],"metadata":{"id":"GL8l1tdLp1cl"}},{"cell_type":"markdown","source":["#### Chart - 14 - Correlation Heatmap"],"metadata":{"id":"NC_X3p0fY2L0"}},{"cell_type":"markdown","source":["# **Hierarchical clustering**"],"metadata":{"id":"ZbqJd5nY8JhG"}},{"cell_type":"markdown","source":["Hierarchical clustering is a method of clustering data points into a tree-like structure. It is an alternative method to k-means clustering and it is used to group similar data points together in a hierarchical fashion.\n","\n","There are two main types of Hierarchical clustering: Agglomerative and Divisive. Agglomerative is a bottom-up approach where each data point is considered as a separate cluster and the algorithm iteratively merges the closest clusters. On the other hand, Divisive is a top-down approach where all data points are considered as a single cluster and the algorithm iteratively splits the clusters.\n","\n","The hierarchical clustering algorithm can be represented by a dendrogram which makes it easy to visualize the structure of the clusters."],"metadata":{"id":"ffTyicqL8NDG"}},{"cell_type":"code","source":["# Correlation Heatmap visualization code\n","# Building a dendogram to decide the number of clusters\n","plt.figure(figsize=(10, 5))\n","dend = shc.dendrogram(shc.linkage(X, method='ward'))\n","plt.title('Dendrogram')\n","plt.xlabel('Netflix Shows')\n","plt.ylabel('Distance')\n","plt.axhline(y= 4, color='r', linestyle='--')"],"metadata":{"id":"xyC9zolEZNRQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fitting hierarchical clustering model\n","hierarchical = AgglomerativeClustering(n_clusters=7, affinity='euclidean', linkage='ward')\n","hierarchical.fit_predict(X)"],"metadata":{"id":"oNisplAo8XAP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Adding a hierarchical cluster number attribute\n","df['hierarchical_cluster'] = hierarchical.labels_"],"metadata":{"id":"9CpTYgaZ8Yhe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.sample(5)[['type', 'title', 'director', 'cast', 'country', 'rating', 'listed_in', 'description', 'hierarchical_cluster']]"],"metadata":{"id":"kqWpminN8Y85"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Number of movies and tv shows in each cluster\n","plt.figure(figsize=(10,5))\n","graph = sns.countplot(x='hierarchical_cluster',data=df, hue='type')\n","plt.title('Number of movies and tv shows in each cluster - Hierarchical Clustering')\n","\n","# adding value count on the top of bar\n","for p in graph.patches:\n","   graph.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))"],"metadata":{"id":"Od1TDmDn8hzy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Building wordclouds for different clusters in hierarchical Clustering**"],"metadata":{"id":"vMV-MtO88puk"}},{"cell_type":"code","source":["def hierarchical_worldcloud(cluster_number, column_name):\n","\n","  '''function for Building a wordcloud for the movie/shows'''\n","\n","  df_wordcloud = df[['hierarchical_cluster',column_name]].dropna()\n","  df_wordcloud = df_wordcloud[df_wordcloud['hierarchical_cluster']==cluster_number]\n","\n","  # text documents\n","  text = \" \".join(word for word in df_wordcloud[column_name])\n","\n","  # create the word cloud\n","  wordcloud = WordCloud(stopwords=set(STOPWORDS), background_color=\"white\").generate(text)\n","\n","  # Generate a word cloud image\n","  plt.imshow(wordcloud, interpolation='bilinear')\n","  plt.axis(\"off\")\n","  plt.show()"],"metadata":{"id":"Aeva5Z0_8uTQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Word Cloud on \"title\" column for different cluster ##\n","for i in range(7):\n","  print(f'cluster {i}')\n","  hierarchical_worldcloud(i,'title')"],"metadata":{"id":"1w2nWBhs89tg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Word Cloud on \"description\" column for different cluster ##\n","for i in range(7):\n","  print(f'cluster {i}')\n","  hierarchical_worldcloud(i,'description')"],"metadata":{"id":"d6JW38He9w2M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Word Cloud on \"country\" column for different cluster ##\n","for i in range(7):\n","  print(f'cluster {i}')\n","  hierarchical_worldcloud(i,'country')"],"metadata":{"id":"EjgPYURO9zya"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Word Cloud on \"listed_in (genre)\" column for different cluster ##\n","for i in range(7):\n","  print(f'cluster {i}')\n","  hierarchical_worldcloud(i,'listed_in')"],"metadata":{"id":"e5tqIMdL97hq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"UV0SzAkaZNRQ"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","word cloud is a visual representation of text data where words are displayed in different sizes, with the size of each word indicating its frequency or importance in the given text.WordCloud library simplifies the process of creating visually appealing word clouds and aids in understanding and communicating the key information within a textual dataset."],"metadata":{"id":"DVPuT8LYZNRQ"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"YPEH6qLeZNRQ"}},{"cell_type":"markdown","source":["Answer Here"],"metadata":{"id":"bfSqtnDqZNRR"}},{"cell_type":"markdown","source":["# **Recommendation System**"],"metadata":{"id":"pCR9CIJO-bsa"}},{"cell_type":"markdown","source":["A content-based recommendation system is a type of recommendation system that suggests items to users based on their similarity to other items that the user has shown interest in. It uses the attributes or features of the items to determine the similarity between them.\n","\n","* Based on how similar the movies and shows are, we can create a straightforward content-based recommender system.\n","* The recommender system needs to be able to suggest a list of similar shows that a person who has watched a show on Netflix likes.\n","* We can use cosine similarity to determine the shows' similarity scores.\n","* By dividing the dot product of the two vectors by their magnitude values, the similarity between A and B can be calculated. Simply put, the angle between two vectors decreases as the cosine similarity score increases."],"metadata":{"id":"1x5disxX-dNu"}},{"cell_type":"code","source":["# veryfying index\n","df[['show_id', 'title', 'text_data']]"],"metadata":{"id":"iH1aAAmI-hYW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Our dataframe has a total of 7770 rows, as shown above, and the last index is 7786 due to the deletion of some rows while treating null values.\n","\n","* In order to construct a content-based recommendation system, we determine the similarity score based on a specific index_id for that particular \"tags\" column.\n","\n","* If we are unable to reset the index, there is a good chance that instead of providing an index, we will calculate cosine similarity for another index. in order to avoid this issue and properly address index when developing the recommendation system. The index was simply reset."],"metadata":{"id":"zBDmUn46-kAE"}},{"cell_type":"code","source":["# defining new dataframe for building recommandation system\n","recommender_df = df.copy()\n","\n","# reseting index\n","recommender_df.reset_index(inplace=True)\n","\n","# checking whether or not reset index properly\n","recommender_df[['show_id', 'title', 'text_data']]"],"metadata":{"id":"OXr8hfzJ-nbz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dropping show-id and index column\n","recommender_df.drop(columns=['index', 'show_id'], inplace=True)"],"metadata":{"id":"XrHQ-Zkh-s4x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"before reset index id for movie 'Zero' : {df[df['title'] == 'Zozo'].index[0]}\")\n","print(f\"after reset index id for movie 'Zero': {recommender_df[recommender_df['title'] == 'Zozo'].index[0]}\")"],"metadata":{"id":"yeQUE_dO-zon"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calling out transformed array independent features created from text_data(cluster) column after performing PCA for dimenssionality reduction.\n","X"],"metadata":{"id":"mAYCQJWz-69K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculate cosine similarity\n","similarity = cosine_similarity(X)\n","similarity"],"metadata":{"id":"pNJ0rBb3-7kc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def recommend(movie):\n","    '''\n","    This function list down top ten movies on the basis of similarity score for that perticular movie.\n","    '''\n","    print(f\"If you liked '{movie}', you may also enjoy: \\n\")\n","\n","    # find out index position\n","    index = recommender_df[recommender_df['title'] == movie].index[0]\n","\n","    # sorting on the basis of simliarity score, In order to find out distaces from recommended one\n","    distances = sorted(list(enumerate(similarity[index])), reverse=True, key=lambda x:x[1])\n","\n","    # listing top ten recommenaded movie\n","    for i in distances[1:11]:\n","        print(df.iloc[i[0]].title)"],"metadata":{"id":"3jVQnOkc-91s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 15 - Pair Plot"],"metadata":{"id":"q29F0dvdveiT"}},{"cell_type":"code","source":["# Pair Plot visualization code"],"metadata":{"id":"o58-TEIhveiU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"EXh0U9oCveiU"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"eMmPjTByveiU"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"22aHeOlLveiV"}},{"cell_type":"markdown","source":["Answer Here"],"metadata":{"id":"uPQ8RGwHveiV"}},{"cell_type":"markdown","source":["## **5. Solution to Business Objective**"],"metadata":{"id":"JcMwzZxoAimU"}},{"cell_type":"markdown","source":["#### What do you suggest the client to achieve Business Objective ?\n","Explain Briefly."],"metadata":{"id":"8G2x9gOozGDZ"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","To achieve the business objective ,the client can follow the following steps:\n","\n","Data Collection: Gather data on the Netflix shows, including attributes such as show titles, genres, descriptions, and ratings. The more data available, the better the clustering results.\n","\n","Data Preprocessing: Clean and preprocess the data to handle missing values, remove irrelevant information, and convert textual data into a suitable format for analysis.\n","\n","Feature Extraction: Extract relevant features from the data that can capture the essence of each show. This can include using natural language processing techniques to extract keywords from show descriptions or using numerical features such as ratings and duration.\n","\n","Clustering Algorithm Selection: Choose appropriate clustering algorithms such as K-Means, hierarchical clustering, or DBSCAN, depending on the data and the desired characteristics of the clusters.\n","\n","Hyperparameter Tuning: If using machine learning-based clustering algorithms, perform hyperparameter tuning to optimize the clustering performance.\n","\n","Evaluation: Evaluate the quality of the clustering results using internal and/or external clustering evaluation metrics to ensure that the shows within each cluster are similar and different across clusters.\n","\n","Personalization: Once the shows are grouped into clusters, use user viewing history and preferences to provide personalized show recommendations. This can be achieved through collaborative filtering or content-based filtering methods.\n","\n","\n","Continuous Improvement: Regularly update the clustering model and show recommendation algorithms based on user feedback and new data to continuously improve the user experience and retention."],"metadata":{"id":"pASKb0qOza21"}},{"cell_type":"markdown","source":["# **Conclusion**"],"metadata":{"id":"gCX9965dhzqZ"}},{"cell_type":"markdown","source":["Write the conclusion here.\n","\n","In this project, we tackled a text clustering problem in which we had to categorize and group Netflix shows into specific clusters in such a way that shows in the same cluster are similar to one another and shows in different clusters are not.\n","\n","* There were approximately 7787 records and 11 attributes in the dataset.\n","* We started by working on the missing values in the dataset and conducting exploratory data analysis (EDA).\n","* It was discovered that Netflix hosts more movies than television shows on its platform, and the total number of shows added to Netflix is expanding at an exponential rate. Additionally, most of the shows were made in the United States.\n","* The attributes were chosen as the basis for the **clustering of the data: cast, country, genre, director, rating, and description** The TFIDF vectorizer was used to tokenize, preprocess, and vectorize the values in these attributes.\n","* **10000 attributes** in total were created by **TFIDF vectorization**.\n","The problem of dimensionality was dealt with through the **use of Principal Component Analysis (PCA). Because 3000 components were able to account for more than 80% of the variance**, the total number of components was limited to 3000.\n","* Utilizing the **K-Means Clustering algorithm**, we first constructed clusters, and the **optimal number of clusters was determined to be 6**. The **elbow method and Silhouette score analysis** were used to get this.\n","* The **Agglomerative clustering algorithm** was then used to create clusters, and the **optimal number of clusters was determined to be 7**. This was obtained after visualizing the **dendrogram**.\n","* The similarity matrix generated by applying **cosine similarity** was used to construct a **content-based recommender system**. The user will receive ten recommendations from this recommender system based on the type of show they watched."],"metadata":{"id":"Fjb1IsQkh3yE"}},{"cell_type":"markdown","source":["### ***Hurrah! You have successfully completed your EDA Capstone Project !!!***"],"metadata":{"id":"gIfDvo9L0UH2"}}]}